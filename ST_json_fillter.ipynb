{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ST1:将json合并\n",
    "将两个json合并并保存到另外一个文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并完成，结果已保存到: /storage/human_psd/json/fp_llz_mer.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def merge_json_to_array(file1_path, file2_path, output_path):\n",
    "    \"\"\"将两个JSON文件合并为一个JSON数组\"\"\"\n",
    "    try:\n",
    "        # 读取第一个JSON文件\n",
    "        with open(file1_path, 'r', encoding='utf-8') as f1:\n",
    "            data1 = json.load(f1)\n",
    "        \n",
    "        # 读取第二个JSON文件\n",
    "        with open(file2_path, 'r', encoding='utf-8') as f2:\n",
    "            data2 = json.load(f2)\n",
    "        \n",
    "        # 合并为数组\n",
    "        merged_data = [*data1, *data2]\n",
    "        \n",
    "        # 确保输出目录存在\n",
    "        output_dir = os.path.dirname(output_path)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # 保存合并后的JSON\n",
    "        with open(output_path, 'w', encoding='utf-8') as out_file:\n",
    "            json.dump(merged_data, out_file, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"合并完成，结果已保存到: {output_path}\")\n",
    "        return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"错误: 合并JSON时出错 - {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# # 使用示例\n",
    "# if __name__ == \"__main__\":\n",
    "file1 = \"/storage/human_psd/json/fp_v1.json\"    # 替换为第一个JSON文件路径\n",
    "file2 = \"/storage/human_psd/json/tao_llz.json\"   # 替换为第二个JSON文件路径\n",
    "output = \"/storage/human_psd/json/fp_llz_mer.json\"  # 替换为输出路径\n",
    "\n",
    "merge_json_to_array(file1, file2, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ST2：获取id\n",
    "获取某个文件夹所有图片文件的id保存为json\n",
    "例如：\n",
    "0618_tao_llz_b0291fd717_2_80.png\n",
    "0618_tao_llz_b0291fd717_2_23.png\n",
    "id为0618_tao_llz_b0291fd717\n",
    "0618_freepik_v1_0be3e0f79d_2_5.png\n",
    "0618_freepik_v1_0be3e0f79d_2_6.png\n",
    "id为0618_freepik_v1_0be3e0f79d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "处理文件: 100%|██████████| 254/254 [00:00<00:00, 259588.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功将 254 个ID保存到 '/storage/human_psd/json/fp_v2_id.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_id_from_filename(filename):\n",
    "    \"\"\"\n",
    "    从图片文件名中提取ID\n",
    "    \n",
    "    参数:\n",
    "    filename (str): 图片文件名\n",
    "    \n",
    "    返回:\n",
    "    str: 提取到的ID，如果无法提取则返回None\n",
    "    \"\"\"\n",
    "    # 正则表达式模式，用于匹配ID部分\n",
    "    pattern = r'^(.+?)_\\d+_\\d+\\.png$'\n",
    "    match = re.match(pattern, filename)\n",
    "    \n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "def get_image_ids_from_folder(folder_path, extensions=['.png', '.jpg', '.jpeg']):\n",
    "    \"\"\"\n",
    "    从文件夹中获取所有图片文件的ID\n",
    "    \n",
    "    参数:\n",
    "    folder_path (str): 文件夹路径\n",
    "    extensions (list): 支持的图片文件扩展名，默认为['.png', '.jpg', '.jpeg']\n",
    "    \n",
    "    返回:\n",
    "    list: 提取到的ID列表\n",
    "    \"\"\"\n",
    "    # 用于存储提取到的ID\n",
    "    ids = []\n",
    "    \n",
    "    # 检查文件夹是否存在\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"错误：文件夹 '{folder_path}' 不存在\")\n",
    "        return ids\n",
    "    \n",
    "    # 获取文件夹中的所有文件\n",
    "    files = os.listdir(folder_path)\n",
    "    \n",
    "    # 使用tqdm显示进度条\n",
    "    for filename in tqdm(files, desc=\"处理文件\"):\n",
    "        # 检查文件扩展名\n",
    "        file_ext = os.path.splitext(filename)[1].lower()\n",
    "        if file_ext in extensions:\n",
    "            # 提取ID\n",
    "            file_id = extract_id_from_filename(filename)\n",
    "            if file_id:\n",
    "                ids.append(file_id)\n",
    "    \n",
    "    return ids\n",
    "\n",
    "def save_ids_to_json(ids, output_path):\n",
    "    \"\"\"\n",
    "    将ID列表保存到JSON文件\n",
    "    \n",
    "    参数:\n",
    "    ids (list): ID列表\n",
    "    output_path (str): 输出JSON文件路径\n",
    "    \"\"\"\n",
    "    # 确保输出文件夹存在\n",
    "    output_dir = os.path.dirname(output_path)\n",
    "    if output_dir and not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 保存ID列表到JSON文件\n",
    "    try:\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(ids, f, ensure_ascii=False, indent=4)\n",
    "        print(f\"成功将 {len(ids)} 个ID保存到 '{output_path}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"错误：无法保存JSON文件 '{output_path}': {str(e)}\")\n",
    "\n",
    "# def main():\n",
    "#     \"\"\"主函数，处理命令行参数\"\"\"\n",
    "#     parser = argparse.ArgumentParser(description='从图片文件名中提取ID并保存到JSON文件')\n",
    "#     parser.add_argument('-i', '--input', required=True, help='包含图片文件的文件夹路径')\n",
    "#     parser.add_argument('-o', '--output', required=True, help='输出JSON文件路径')\n",
    "#     parser.add_argument('-e', '--extensions', nargs='+', default=['.png', '.jpg', '.jpeg'], \n",
    "#                         help='支持的图片文件扩展名，默认为 .png .jpg .jpeg')\n",
    "    \n",
    "#     args = parser.parse_args()\n",
    "extensions=['.png', '.jpg', '.jpeg']\n",
    "input_path='/storage/human_psd/img_human_detected/filltered/fp_v2'\n",
    "output_path='/storage/human_psd/json/fp_v2_id.json'\n",
    "\n",
    "# 获取图片ID\n",
    "ids = get_image_ids_from_folder(input_path, extensions)\n",
    "\n",
    "# 保存到JSON文件\n",
    "if ids:\n",
    "    save_ids_to_json(ids, output_path)\n",
    "else:\n",
    "    print(\"警告：未找到任何有效的图片文件或无法提取ID\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ST3:过滤json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_json_path='/storage/human_psd/json/fp_v2.json'\n",
    "with open(merge_json_path, 'r', encoding='utf-8') as f1:\n",
    "    data1 = json.load(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 528/528 [00:00<00:00, 82455.60it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "fillter_data=[]\n",
    "\n",
    "for d in tqdm(data1):\n",
    "    if d['id'] in ids:fillter_data.append(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fillter_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_data_path='/storage/human_psd/filltered_json/fillter_fp_v2.json'\n",
    "\n",
    "with open(filter_data_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(fillter_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge_json_path='/storage/human_psd/json/fp_llz_mer.json'\n",
    "with open(filter_data_path, 'r', encoding='utf-8') as f1:\n",
    "    test_m_data = json.load(f1)\n",
    "\n",
    "len(test_m_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
